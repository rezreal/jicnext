<!DOCTYPE html>
<head>

<!-- http://127.0.0.1:8080 -->
<meta http-equiv="origin-trial" content="Ag24G4dj6zBN/qOusNuQmRq3gl0rgMFSbdAct1MPVRhNGDTPRldJaIkBJlqSz0YeOAP4sFNX7NLuMzxwaRJNdQwAAABReyJvcmlnaW4iOiJodHRwOi8vMTI3LjAuMC4xOjgwODAiLCJmZWF0dXJlIjoiU2hhcGVEZXRlY3Rpb24iLCJleHBpcnkiOjE1NTE4MzAzOTl9">
<!-- https://rezreal.github.io -->
<meta http-equiv="origin-trial" content="AkXnCCaN+yKfbW5fxjeSS8SCFeFxWIoJ9cQEx5UeIbSQrX+J7lYkmg1pSFft0JH+JJ5/y0vWmlCZOe0uULTWLQcAAABZeyJvcmlnaW4iOiJodHRwczovL3JlenJlYWwuZ2l0aHViLmlvOjQ0MyIsImZlYXR1cmUiOiJTaGFwZURldGVjdGlvbiIsImV4cGlyeSI6MTU1MTgzMDM5OX0=">
<link rel="stylesheet" type="text/css" href="style.css">
<script src="https://webrtc.github.io/adapter/adapter-latest.js" referrerpolicy="no-referrer"></script>
<script src="speech.js"></script>
<script src="video.js"></script>

<script type="text/javascript">
/* Image Attr */
    /**
     * @param {HTMLCanvasElement} acanvas
     * @return { {brightness: number, contrast: number} }
     **/
   function getImageAttr(acanvas) {
          let colorSum = 0;
          let cMin = 255;
          let cMax = 0;

            let ctx = acanvas.getContext("2d");
            ctx.drawImage(acanvas,0,0);

            const imageData = ctx.getImageData(0,0,acanvas.width,acanvas.height);
            const data = imageData.data;
            var r,g,b,avg;

          for(let x = 0, len = data.length; x < len; x+=4) {
                r = data[x];
                g = data[x+1];
                b = data[x+2];

                avg = Math.floor((r+g+b)/3);
				if (cMin > avg)
				  cMin = avg;
				if (cMax < avg)
				  cMax = avg;
                colorSum += avg;
            }


              return {
                  contrast: cMax-cMin,
                  brightness: Math.floor(colorSum / (acanvas.width*acanvas.height))
              };

    }

/*
  Script for main task
*/
let ended = false;
function exittask() {
  if (ended === false) {
    return "Are you sure you want to leave this page? if you leave early you will be exposed!";
  }
}

function addlog(ltext){
    document.getElementById('logmsg').value = ltext;
  const fd2 = new FormData(document.forms["form2"]);
  console.info("normally now we would send stuff to jenniffer:", fd2);
}

//script code
var cline = 0;
var msgtext = "";
// User values
var level = 0;
var real_name = "";
var user_email = "";
let recorded_audio_blobs = [];


function runtask(){

	if (window.currentRecognition) {
		window.currentRecognition.stop();
		window.currentRecognition = undefined;
	}

  // Process Values
  switch (cline) {
    case 0: level = 1;
	        break;
    case 2: real_name = document.getElementById("username").value;
	        user_email = document.getElementById("useremail").value;
			fetlife = document.getElementById("fetlife").value;
			referred = document.getElementById("referred").value;
			
			if ((real_name === "") || (user_email === "")) {
				two.innerHTML = "";
				three.innerHTML = "";
			  	say("Well that's an interesting name and email-address. Think we will have to try again.").then(idle(2000)).then(runtask);
				cline = 1; // actually two but it is incremented
				return;
            }
	        break;
  }
  cline++;
  three.innerHTML = ""; // clear buttons
  switch (cline) {
      case 1:
	      if (workingcam) {
			one.src="lib_image/jen1.jpg";
			two.innerHTML = "";
			say("Well hello there, It's nice to meet you, what do you think we should do?").then(idle(1000)).then(runtask);
            
			
          } else {
			two.innerHTML = "Ohh you failed at the first step! I can't see your camera.. try looking at the FAQ for more help.";
			cline = 180;
          }			  
	      break;
      case 2:
//	      one.src="lib_image/01.jpg";  
          one.src="lib_image/jen2.jpg";
		  say('But before we get started I think it would be nice to know a little about you? Please say "I am ready" when you have entered your details.')
              .then(() => choose('I am ready', runtask, () => say('I could not understand you. Please say "I am ready" when you are ready.')));
 	      three.innerHTML = "Name: <input type=\"text\" name=\"msg\" id=\"username\" size=\"20\"><br>Email: <input type=\"email\" name=\"msg\" id=\"useremail\" size=\"40\"><br>Fetlife username (if have one): <input type=\"text\" name=\"msg\" id=\"fetlife\" size=\"20\"><br>Referred by (if anyone): <input type=\"text\" name=\"msg\" id=\"referred\" size=\"20\">";
	      break;
      case 3:
          one.src="lib_image/jen3.jpg";

		say(`Ok ${real_name}, you look like you have a bulge in your trousers already and we haven't even got started. Shall we play a little game of you show me yours and then I will show you mine? and then we may have a little play after that`);
		say('When you are ready say "Yes, sounds fun"')
            .then(() => choose('yes sounds fun', runtask, () => say('I could not understand you, please repeat')));
		addlog("Level:" + level);
	    addlog("Name:" + real_name);
	    addlog("Fetlife:" + fetlife);
	    addlog("Referred:" + referred);
		addlog("Sex:Male");
		addlog("Orientation:Heterosexual");
		send_photo();
		break;
      case 4:
          one.src="lib_image/jen4.jpg";
	      two.innerHTML = "";
		  say("Do you feel adventurous today " + real_name + "? yes or no?").then(() => choose(['yes', 'no'], [runtask, ()=> {cline = 98; runtask(); return true;}]));
	      break;
      case 5:
	  	  say("I really like to hear you speak to me. I want you to repeat after me the following sentence until you filled the bar. Are you ready")
              .then(() => choose(['yes', 'no'], [runtask, ()=> {cline = 98; runtask();}]));
		break;
      case 6:

          two.innerHTML = "Repeat after me!: ";
          three.innerHTML = `<progress max="1" value="0" id="progress">`;
          let progress = 0.1;
          document.getElementById('progress').value = progress;

          function onProgress(continueCb) {
              progress += 0.20;
              document.getElementById('progress').value = progress;

              if (progress >= 1) {
                  say("Congratulations! You made it!").then(runtask);
              } else {
                  continueCb();
              }
          }

          function onMistake() {
              progress -= 0.05;
              document.getElementById('progress').value = progress;
              return document.getElementById("buzzer").play().then(idle(1000));
          }

          repeatAfterMe(['ABC', 'my name is',
              'the answer of life the universe and everything is 42',
              'i believe in pink unicorns',
              'I could do this the whole day', 'I know a nice pancake recipe', 'any time of the day is a good time for pie',
              'Why do you think are we doing this'], onProgress, ()=>undefined, onMistake);

          break;

      case 7:
          two.innerHTML = '';
          three.innerHTML = '';
          say('Now as a last in your initiation step we will do the paperwork.')
              .then(() => say('I want you to read the following displayed consent text aloud. Clear and slowly.'))
              .then(() => say('Make sure that you mean what you say.'))
              .then(runtask);
          break;
      case 8: {
          two.innerHTML = 'Please read slowly and clearly:';
          three.innerHTML = '';

          let sentenceNo = 0;
          function beforeNextSentence(nextSentence) {
              if (!document.querySelector(`.recordSentence.no${sentenceNo}`)) {
                  three.innerHTML += `<span class="recordSentence currentSentence no${sentenceNo}">${nextSentence}</span>&emsp;`
              }
          }

          function afterSentence() {
              document.querySelectorAll('.currentSentence').forEach((el) => el.classList.remove('currentSentence'));
              sentenceNo++;
          }

          recordAll([`My name is ${real_name}.`, 'I am at least 18 years old.', 'I understand that this is not a game.', 'Hereby I submit myself to Mistress Jennifer.', 'I will obey her commands.', 'I will not question her authority.', 'I will do my tasks.',
                     'I will suffer to amuse her.', 'I consent to do whatever she wants me to do.'], beforeNextSentence, afterSentence)
              .then((b)=>{ recorded_audio_blobs = b })
              .then(() => say("Thanks for your cooperation! We will keep a copy of your spoken consent for the records. You may rehear it now."))
              .then(idle(1000))
              .then(() => playAudioBlob(recorded_audio_blobs[0]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[1]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[2]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[3]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[4]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[5]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[6]))
              .then(idle(500))
              .then(() => playAudioBlob(recorded_audio_blobs[7]))
              .then(idle(500))
              .then(() => say('Amazing. Now give us some time to let our A I work through your application. You will hear back from us soon.'));
          break;
      }
      case 99:
          one.src="lib_image/jen1.jpg";
          say("Oh that is too bad. See you. Reload the page to start over again.");
          break;
	}
}
</script>
</head>

<body onbeforeunload="return exittask()">

	<audio src="camera_click.ogg" preload="auto" id="camera_click"></audio>
	<audio src="siri_start.ogg" preload="auto" id="siri_start"></audio>
	<audio src="siri_end.ogg" preload="auto" id="siri_end"></audio>
	<audio src="portal2buzzer.mp3" preload="auto" id="buzzer"></audio>

	<img id="one" src="lib_image/jen1.jpg" width="100%" />
<div id="mtext">
<div id="messagebox">
<p  id="two" >Loading task...</p>
</div>
<br>
<form>
<p id="three" >&nbsp;</p>
<img src="microphone.svg" id="mic" />

<!-- <button style="height:50px;" onclick="runtask();">restart script</button> -->
</form>

<form method="post" accept-charset="utf-8" name="form2">
<input name="id" value="2Z7791161"  type="hidden"/>
 <input name="msg" id='logmsg' type="hidden"/>
</form>
</div>
<!-- Video capture - should hide? -->

<div id="container">
    <label for="videoSource">Source: </label>
    <fieldset id="videoSource"></fieldset>
    <label for="hideFace">Hide Face</label> <input name="hideFace" id="hideFace" type="checkbox" checked><br/>
    <button onclick="send_photo()">Force Photo</button>
    <button onclick="this.disabled = true; send_clip(3000); setTimeout(()=>this.disabled = false, 3000)">Force Clip</button>

</div>

    <div id="videoContainer"></div>

    <form method="post" accept-charset="utf-8" name="form1">
        <input name="id" value="2Z7791161"  type="hidden"/>
        <input name="hidden_data" id='hidden_data' type="hidden"/>
    </form>

    <div id="debugGallery">
        <h3>Debug Gallery</h3>
    </div>

    <canvas style="visibility: hidden; position: absolute;" id="canvas" width="640" height="480"></canvas>
    <script>
var workingcam = true;
var reallyWorkingcam = true;
var workingmic = true;
const videoContainer = document.getElementById('videoContainer');
const videoSelect = document.getElementById('videoSource');
const hideFaceCheckbox = document.getElementById('hideFace');
var hideFace = true;

if (!window.FaceDetector) {
    hideFaceCheckbox.enabled = false;
    hideFaceCheckbox.checked = false;
    hideFace = false;
}
const faceDetector = (window.FaceDetector) ? new FaceDetector({ maxDetectedFaces: 1, fastMode: false}) : undefined;

hideFaceCheckbox.addEventListener('change', (e) => hideFace = e.target.checked);


/**
 * @type {Array<VideoStreamRecord>}
 */
let activeVideoRecords = [];

/**
 * @type {Array<MediaStreamTrack>}
 **/
let activeAudioStreamTracks = [];

navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia || navigator.oGetUserMedia;
 
if (navigator.getUserMedia) {
    navigator.getUserMedia({audio: true}, handleAudio, audioError);
}

loadVideoDevicesList().then((deviceIds) => {
    // automatically start the first video device
    if (deviceIds.length > 0) {
        requestStartVideoDevice([deviceIds[0]]);
    }
});

/**
 * @param {MediaStream} stream
 */
function handleAudio(stream) {
    activeAudioStreamTracks = [...activeAudioStreamTracks, ...stream.getAudioTracks()];
}

/**
 * @return {Promise<Array<string>>} - an array of video device ids
 */
function loadVideoDevicesList() {

// the filling of the select is only done if the select is empty

    if (navigator.mediaDevices  && navigator.mediaDevices.enumerateDevices && videoSelect) {
        return navigator.mediaDevices.enumerateDevices()
            .then(function (deviceInfos) {

                videoSelect.innerHTML = ''; // drop options
                const options = [];
                const videoInfos = deviceInfos.filter(di => di.kind === 'videoinput');
                videoInfos
                    .forEach((deviceInfo, i) => {
                        const container = document.createElement('div');
                        const label = document.createElement('label');
                        label.textContent = deviceInfo.label || 'camera ' + (videoSelect.length + 1);
                        /** @type HTMLInputElement */
                        const checkbox = document.createElement('input');
                        checkbox.type = 'checkbox';
                        checkbox.value = deviceInfo.deviceId;
                        checkbox.onchange = onStreamToggled;
                        checkbox.checked = i === 0;
                        container.appendChild(label);
                        container.appendChild(checkbox);
                        videoSelect.appendChild(container);
                        options.push(checkbox);
                    });


                return videoInfos.map(di => di.deviceId);
            })
            .catch(console.error);
    } else {
        return Promise.reject('no mediaDevice support');
    }
}



/**
 * @param {string} deviceId
 * @param {MediaStream} stream
 */
function handleNewVideoStream(deviceId, stream) {

    if (stream.getTracks().length !== 1) {
        throw new Error('expected only one track for an exact match query');
    }
    const track = stream.getTracks()[0];
    /**
     * @type {HTMLVideoElement}
     */
    const videoElement = document.createElement('video');
    videoElement.addEventListener('click', () => togglePip(videoElement));

    videoElement.autoplay = true;
    const isFirst = videoContainer.childElementCount === 0;
    if (isFirst) {
        videoElement.autoPictureInPicture = true;
    }

    videoContainer.appendChild(videoElement);
    try  {
        videoElement.src = window.URL.createObjectURL(track);
	} catch(e){
        videoElement.srcObject = stream;
	}

    /**
     * @type {VideoStreamRecord}
     */
	const videoStream = { id: deviceId, videoElement, stream, track};
    activeVideoRecords.push(videoStream);
}


/** @param {Event} event */
function onStreamToggled(event) {

    const checked = event.target.checked;
    const streamId = event.target.value;
    const activeVideoRecordIds = activeVideoRecords.map(record => record.id);

    const toStartIds = (checked?[streamId]:[]).filter(x => !activeVideoRecordIds.includes(x));

    const toStopVideos = activeVideoRecords.filter(x => !checked && x.id === streamId);

    activeVideoRecords = activeVideoRecords.filter(x => !(!checked && x.id === streamId));

    toStopVideos.forEach(toStopVideo => {
            toStopVideo.track.stop();
            if (toStopVideo.videoElement.url) {
                URL.revokeObjectURL(toStopVideo.videoElement.url); // trying to be clean
            }
            toStopVideo.videoElement.parentElement.removeChild(toStopVideo.videoElement);
        });
    requestStartVideoDevice(toStartIds);
}

/** @param {string[]} deviceIds */
function requestStartVideoDevice(deviceIds) {
    deviceIds
        .map(deviceId => ({
            video: {deviceId: {exact: deviceId}},
            audio: false}))
        .forEach(constraint => navigator.getUserMedia(constraint, handleNewVideoStream.bind(null, constraint.video.deviceId.exact), videoError));
}
 
function videoError(e) {
	console.info('video error', e);
	reallyWorkingcam = false;
}

function audioError(e) {
	console.info('audio error', e);
	workingmic = false;
}



function send_photo(secret) {

    if (!secret) {
        document.getElementById("camera_click").play();
        document.getElementById("one").classList.add("shutterClick");
        setTimeout(() => document.getElementById("one").classList.remove('shutterClick'), 900);
    }




    if (reallyWorkingcam) {
        const canvas = document.getElementById("canvas");
        const context = canvas.getContext("2d");


        const canvasTotalHeight = activeVideoRecords.map(avr => canvas.width / avr.videoElement.videoWidth  * avr.videoElement.videoHeight).reduce((a,b)=>a+b);
        canvas.height = canvasTotalHeight;

        const withFaceDetection = (hideFace) ?
            Promise.all(activeVideoRecords.map((video) => faceDetector.detect(video.videoElement))).finally(console.info)
            : Promise.resolve(Array(activeVideoRecords.length).fill(undefined));

        withFaceDetection.then(faceDetectionResults => {
            console.info(faceDetectionResults);
            let currentY = 0;

            activeVideoRecords.forEach((video, i) => {

                const videoScaleFactor = canvas.width / video.videoElement.videoWidth;
                const projectedHeight = videoScaleFactor * video.videoElement.videoHeight;
                context.drawImage(video.videoElement, 0, currentY, canvas.width, projectedHeight);

                const face = (faceDetectionResults[i]||[])[0];
                if (face) {
                    const bb = face.boundingBox;
                    context.fillRect(videoScaleFactor*bb.x, videoScaleFactor*bb.y + currentY, videoScaleFactor*bb.width,videoScaleFactor*bb.height);
                }

                currentY += projectedHeight;
            });


            const {brightness, contrast} = getImageAttr(canvas);

            if ((brightness > 50) && (contrast > 50)) {
                const dataURL = canvas.toDataURL("image/png");
                document.getElementById('hidden_data').value = dataURL;
                const fd = new FormData(document.forms["form1"]);
                /**
                 const xhr = new XMLHttpRequest();
                 xhr.open('POST', 'jen_pic.php', true);
                 xhr.upload.onprogress = function(e) {
                };
                 xhr.onload = function() {
                    var u_image = xhr.responseText;
                    };
                 one.src = dataURL;
                 // nope, we are not sending anything
                 xhr.send(fd);
                 */
                fakeSendImage(dataURL);
            }



        });
    }
}


function fakeSendImage(dataUrl) {
    const galleryDiv = document.getElementById('debugGallery');
    /** @type {HTMLImageElement}*/
    const img = document.createElement('img');
    img.src = dataUrl;
    galleryDiv.appendChild(img);

}


function send_clip(durationMillis) {
    const audioTrack = activeAudioStreamTracks.length > 0 ?  activeAudioStreamTracks[0] : undefined;
    // record each active camera but only the first with audio
    activeVideoRecords.forEach((videoTrack, index) => {
        const first = index === 0;
        recordClip(videoTrack.track, first ? audioTrack : undefined, durationMillis)
            .then(fakeSendClip);
    });
}

function fakeSendClip(dataUrl) {
    const galleryDiv = document.getElementById('debugGallery');

    /** @type {HTMLVideoElement}*/
    const video = document.createElement('video');
    video.autoplay = false;
    video.controls = true;
    video.defaultMuted = false;
    video.src = dataUrl;
    galleryDiv.appendChild(video);

}

</script>

<script>
// Start script
//window.onload = function() {
//    runtask();
//};
</script>
	<button onClick="runtask();">Start</button>


</body>

</html>
